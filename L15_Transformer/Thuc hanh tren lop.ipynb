{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Thuc hanh tren lop.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3.8.10 64-bit"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}},"cells":[{"cell_type":"markdown","source":["# Thực hành Transformers"],"metadata":{"id":"vQlWddpo54dw"}},{"cell_type":"markdown","source":["Trong bài này, ta sẽ thực hành cài đặt Transformer"],"metadata":{"id":"OuvnxbLY54d_"}},{"cell_type":"markdown","source":["### 1. Cài đặt và import thư viện"],"metadata":{"id":"rDVST3tm54eB"}},{"cell_type":"code","execution_count":null,"source":["!which python3"],"outputs":[],"metadata":{"id":"3WdMvH4x9swj"}},{"cell_type":"code","execution_count":null,"source":["!pip3 install spacy dill\n","!pip3 install torchtext\n","!pip3 install pandas"],"outputs":[],"metadata":{"id":"I4ObXVBqjGby"}},{"cell_type":"code","execution_count":null,"source":["!python3 -m spacy download en && python3 -m spacy download fr"],"outputs":[],"metadata":{"id":"US4j_5D69swl"}},{"cell_type":"code","execution_count":null,"source":["import torch.nn as nn\n","import torch\n","import torchtext\n","import copy\n","import math\n","import torch.nn.functional as F"],"outputs":[],"metadata":{"id":"OaNedrhUjGb0"}},{"cell_type":"code","execution_count":null,"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"outputs":[],"metadata":{"id":"I6462QxLjGb0"}},{"cell_type":"markdown","source":["### 2. Cài đặt từng module của Transformer"],"metadata":{"id":"SKi4E0bZ54eT"}},{"cell_type":"code","execution_count":null,"source":["class Embedder(nn.Module):\n","    def __init__(self, vocab_size, dim):\n","        super().__init__()\n","        self.embed = nn.Embedding(vocab_size, dim)\n","    \n","    def forward(self, x):\n","        return self.embed(x)"],"outputs":[],"metadata":{"id":"DosoYt1YjGb0"}},{"cell_type":"markdown","source":["**Position Embedding Class**:"],"metadata":{"id":"pBaPrBG0ubI-"}},{"cell_type":"code","execution_count":null,"source":["# Positional encoding\n","class PositionalEncoder(nn.Module):\n","    def __init__(self, dim, max_seq_len=300):\n","        super().__init__()\n","        self.dim = dim\n","        \n","        # create a constant 'pe' matrix with values dependant on \n","        # pos and i\n","        pe = torch.zeros(max_seq_len, dim)\n","\n","        ########################\n","        ##   YOUR CODE HERE   ##\n","        ########################\n","        \n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","        \n","    def forward(self, x):\n","        # make embeddings relatively larger\n","        x = x *math.sqrt(self.dim)\n","        # add constant to embedding\n","        seq_len = x.size(1)\n","        x = x + Variable(self.pe[:, :seq_len], requires_grad=False).to(device)\n","        return x"],"outputs":[],"metadata":{"id":"MJs0_6GwjGb1"}},{"cell_type":"markdown","source":["**Multi Head Attention**: We first start with implementing attention function\n","\n","Attention of $q$"],"metadata":{"id":"F25tcm9tu1ce"}},{"cell_type":"code","execution_count":null,"source":["def attention(q, k, v, d_k, mask=None, dropout=None):\n","    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n","    if mask is not None:\n","        mask = mask.unsqueeze(1)\n","        scores = scores.masked_fill(mask == 0, -1e9)\n","    \n","    scores = F.softmax(scores, dim=-1)\n","    \n","    if dropout is not None:\n","        scores = dropout(scores)\n","        \n","    output = torch.matmul(scores, v)\n","    return output"],"outputs":[],"metadata":{"id":"wJEKoan4jGb2"}},{"cell_type":"code","execution_count":null,"source":["# Multi-headed attention\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, heads, dim, dropout=0.1):\n","        super().__init__()\n","        self.dim = dim\n","        self.dim_head = dim//heads\n","        self.h = heads\n","        self.q_linear = nn.Linear(dim, dim)\n","        self.k_linear = nn.Linear(dim, dim)\n","        self.v_linear = nn.Linear(dim, dim)\n","        self.dropout = nn.Dropout(dropout)\n","        self.out = nn.Linear(dim, dim)\n","    \n","    def forward(self, q, k, v, mask=None):\n","        bs = q.size(0)\n","        # perform linear operation and split into h heads\n","        k = self.k_linear(k).view(bs, -1, self.h, self.dim_head)\n","        q = self.q_linear(q).view(bs, -1, self.h, self.dim_head)\n","        v = self.v_linear(v).view(bs, -1, self.h, self.dim_head)\n","        # transpose to get dimensions bs * h * sl * dim\n","        k = k.transpose(1, 2)\n","        q = q.transpose(1, 2)\n","        v = v.transpose(1, 2)\n","        # calculate attention using the function we will define next\n","        scores = attention(q, k, v, self.dim, mask, self.dropout)\n","        # concatenate heads and put through final linear layer\n","        concat = scores.transpose(1,2).contiguous().view(bs, -1, self.dim)\n","        output = self.out(concat)\n","        return output"],"outputs":[],"metadata":{"id":"4vvVcNXBjGb1"}},{"cell_type":"code","execution_count":null,"source":["class FeedForward(nn.Module):\n","    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n","        super().__init__() \n","        # We set d_ff as a default to 2048\n","        self.linear_1 = nn.Linear(d_model, d_ff)\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear_2 = nn.Linear(d_ff, d_model)\n","    def forward(self, x):\n","        x = self.dropout(F.relu(self.linear_1(x)))\n","        x = self.linear_2(x)\n","        return x"],"outputs":[],"metadata":{"id":"2Cy0Xt9QjGb2"}},{"cell_type":"code","execution_count":null,"source":["class Norm(nn.Module):\n","    def __init__(self, d_model, eps = 1e-6):\n","        super().__init__()\n","    \n","        self.size = d_model\n","        # create two learnable parameters to calibrate normalisation\n","        self.alpha = nn.Parameter(torch.ones(self.size))\n","        self.bias = nn.Parameter(torch.zeros(self.size))\n","        self.eps = eps\n","    def forward(self, x):\n","        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n","        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n","        return norm"],"outputs":[],"metadata":{"id":"v7UTrblYjGb2"}},{"cell_type":"code","execution_count":null,"source":["# build an encoder layer with one multi-head attention layer and one \n","# feed-forward layer\n","class EncoderLayer(nn.Module):\n","    def __init__(self, d_model, heads, dropout = 0.1):\n","        super().__init__()\n","        self.norm_1 = Norm(d_model)\n","        self.norm_2 = Norm(d_model)\n","        self.attn = MultiHeadAttention(heads, d_model)\n","        self.ff = FeedForward(d_model)\n","        self.dropout_1 = nn.Dropout(dropout)\n","        self.dropout_2 = nn.Dropout(dropout)\n","        \n","    def forward(self, x, mask):\n","        ########################\n","        ##   YOUR CODE HERE   ##\n","        ########################\n","    "],"outputs":[],"metadata":{"id":"1uYXmKKsjGb2"}},{"cell_type":"code","execution_count":null,"source":["# build a decoder layer with two multi-head attention layers and\n","# one feed-forward layer\n","class DecoderLayer(nn.Module):\n","    def __init__(self, d_model, heads, dropout=0.1):\n","        super().__init__()\n","        self.norm_1 = Norm(d_model)\n","        self.norm_2 = Norm(d_model)\n","        self.norm_3 = Norm(d_model)\n","        \n","        self.dropout_1 = nn.Dropout(dropout)\n","        self.dropout_2 = nn.Dropout(dropout)\n","        self.dropout_3 = nn.Dropout(dropout)\n","        \n","        self.attn_1 = MultiHeadAttention(heads, d_model)\n","        self.attn_2 = MultiHeadAttention(heads, d_model)\n","        self.ff = FeedForward(d_model).cuda()\n","    \n","    def forward(self, x, e_outputs, src_mask, trg_mask):\n","        ########################\n","        ##   YOUR CODE HERE   ##\n","        ########################\n","\n","def get_clones(module, N):\n","    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"],"outputs":[],"metadata":{"id":"8AWL51G_jGb3"}},{"cell_type":"code","execution_count":null,"source":["class Encoder(nn.Module):\n","    def __init__(self, vocab_size, d_model, N, heads):\n","        super().__init__()\n","        self.N = N\n","        self.embed = Embedder(vocab_size, d_model)\n","        self.pe = PositionalEncoder(d_model)\n","        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n","        self.norm = Norm(d_model)\n","        \n","    def forward(self, src, mask):\n","        ########################\n","        ##   YOUR CODE HERE   ##\n","        ########################\n","    \n","class Decoder(nn.Module):\n","    def __init__(self, vocab_size, d_model, N, heads):\n","        super().__init__()\n","        self.N = N\n","        self.embed = Embedder(vocab_size, d_model)\n","        self.pe = PositionalEncoder(d_model)\n","        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n","        self.norm = Norm(d_model)\n","    def forward(self, trg, e_outputs, src_mask, trg_mask):\n","        ########################\n","        ##   YOUR CODE HERE   ##\n","        ########################"],"outputs":[],"metadata":{"id":"mQAOcVwqjGb3"}},{"cell_type":"code","execution_count":null,"source":["class Transformer(nn.Module):\n","    def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n","        super().__init__()\n","        self.encoder = Encoder(src_vocab, d_model, N, heads)\n","        self.decoder = Decoder(trg_vocab, d_model, N, heads)\n","        self.out = nn.Linear(d_model, trg_vocab)\n","    def forward(self, src, trg, src_mask, trg_mask):\n","        e_outputs = self.encoder(src, src_mask)\n","        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n","        output = self.out(d_output)\n","        return output# we don't perform softmax on the output as this will be handled \n","# automatically by our loss function"],"outputs":[],"metadata":{"id":"TtVVMjazjGb3"}},{"cell_type":"markdown","source":["### 3. Chuẩn bị và tiền xử lý dữ liệu"],"metadata":{"id":"O7dd-47L54eq"}},{"cell_type":"code","execution_count":null,"source":["import spacy\n","import re\n","\n","# Tokenize\n","\n","class tokenize(object):\n","    \n","    def __init__(self, lang):\n","        self.nlp = spacy.load(lang)\n","            \n","    def tokenizer(self, sentence):\n","        sentence = re.sub(\n","        r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", str(sentence))\n","        sentence = re.sub(r\"[ ]+\", \" \", sentence)\n","        sentence = re.sub(r\"\\!+\", \"!\", sentence)\n","        sentence = re.sub(r\"\\,+\", \",\", sentence)\n","        sentence = re.sub(r\"\\?+\", \"?\", sentence)\n","        sentence = sentence.lower()\n","        return [tok.text for tok in self.nlp.tokenizer(sentence) if tok.text != \" \"]"],"outputs":[],"metadata":{"id":"ZY3841jbjGb4"}},{"cell_type":"code","execution_count":null,"source":["# Creating batch\n","from torchtext.legacy import data\n","import numpy as np\n","from torch.autograd import Variable\n","\n","\n","def nopeak_mask(size, opt):\n","    np_mask = np.triu(np.ones((1, size, size)),\n","    k=1).astype('uint8')\n","    np_mask =  Variable(torch.from_numpy(np_mask) == 0)\n","    np_mask = np_mask.to(device)\n","    return np_mask\n","\n","def create_masks(src, trg, opt):\n","    \n","    src_mask = (src != opt.src_pad).unsqueeze(-2)\n","\n","    if trg is not None:\n","        trg.to(device)\n","        trg_mask = (trg != opt.trg_pad).unsqueeze(-2).to(device)\n","        size = trg.size(1) # get seq_len for matrix\n","        np_mask = nopeak_mask(size, opt)\n","        trg_mask = trg_mask & np_mask\n","        \n","    else:\n","        trg_mask = None\n","    return src_mask, trg_mask\n","\n","# patch on Torchtext's batching process that makes it more efficient\n","# from http://nlp.seas.harvard.edu/2018/04/03/attention.html#position-wise-feed-forward-networks\n","\n","class MyIterator(data.Iterator):\n","    def create_batches(self):\n","        if self.train:\n","            def pool(d, random_shuffler):\n","                for p in data.batch(d, self.batch_size * 100):\n","                    p_batch = data.batch(\n","                        sorted(p, key=self.sort_key),\n","                        self.batch_size, self.batch_size_fn)\n","                    for b in random_shuffler(list(p_batch)):\n","                        yield b\n","            self.batches = pool(self.data(), self.random_shuffler)\n","            \n","        else:\n","            self.batches = []\n","            for b in data.batch(self.data(), self.batch_size,\n","                                          self.batch_size_fn):\n","                self.batches.append(sorted(b, key=self.sort_key))\n","\n","global max_src_in_batch, max_tgt_in_batch\n","\n","def batch_size_fn(new, count, sofar):\n","    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n","    global max_src_in_batch, max_tgt_in_batch\n","    if count == 1:\n","        max_src_in_batch = 0\n","        max_tgt_in_batch = 0\n","    max_src_in_batch = max(max_src_in_batch,  len(new.src))\n","    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n","    src_elements = count * max_src_in_batch\n","    tgt_elements = count * max_tgt_in_batch\n","    return max(src_elements, tgt_elements)"],"outputs":[],"metadata":{"id":"xLDB_d_mjGb4"}},{"cell_type":"code","execution_count":null,"source":["import pandas as pd\n","import torchtext\n","from torchtext.legacy import data\n","import os\n","import dill as pickle\n","\n","def read_data(opt):\n","    if opt.src_data is not None:\n","        try:\n","            opt.src_data = open(opt.src_data).read().strip().split('\\n')\n","        except:\n","            print(\"error: '\" + opt.src_data + \"' file not found\")\n","            quit()\n","    \n","    if opt.trg_data is not None:\n","        try:\n","            opt.trg_data = open(opt.trg_data).read().strip().split('\\n')\n","        except:\n","            print(\"error: '\" + opt.trg_data + \"' file not found\")\n","            quit()\n","\n","def create_fields(opt):\n","    spacy_langs = ['en', 'fr', 'de', 'es', 'pt', 'it', 'nl']\n","    src_lang = opt.src_lang[0:2]\n","    trg_lang = opt.trg_lang[0:2]\n","    if src_lang not in spacy_langs:\n","        print('invalid src language: ' + opt.src_lang + 'supported languages : ' + spacy_langs)  \n","    if trg_lang not in spacy_langs:\n","        print('invalid trg language: ' + opt.trg_lang + 'supported languages : ' + spacy_langs)\n","    \n","    print(\"loading spacy tokenizers...\")\n","    \n","    t_src = tokenize(opt.src_lang)\n","    t_trg = tokenize(opt.trg_lang)\n","    TRG = data.Field(lower=True, tokenize=t_trg.tokenizer, init_token='<sos>', eos_token='<eos>')\n","    SRC = data.Field(lower=True, tokenize=t_src.tokenizer)\n","\n","    return(SRC, TRG)\n","\n","def create_dataset(opt, SRC, TRG):\n","\n","    print(\"creating dataset and iterator... \")\n","\n","    raw_data = {'src' : [line for line in opt.src_data], 'trg': [line for line in opt.trg_data]}\n","    df = pd.DataFrame(raw_data, columns=[\"src\", \"trg\"])\n","    \n","    mask = (df['src'].str.count(' ') < opt.max_strlen) & (df['trg'].str.count(' ') < opt.max_strlen)\n","    df = df.loc[mask]\n","\n","    df.to_csv(\"translate_transformer_temp.csv\", index=False)\n","    \n","    data_fields = [('src', SRC), ('trg', TRG)]\n","    train = data.TabularDataset('./translate_transformer_temp.csv', format='csv', fields=data_fields)\n","\n","    train_iter = MyIterator(train, batch_size=opt.batchsize, device=device,\n","                        repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n","                        batch_size_fn=batch_size_fn, train=True, shuffle=True)\n","    \n","    os.remove('translate_transformer_temp.csv')\n","    SRC.build_vocab(train)\n","    TRG.build_vocab(train)\n","    opt.src_pad = SRC.vocab.stoi['<pad>']\n","    opt.trg_pad = TRG.vocab.stoi['<pad>']\n","\n","    opt.train_len = get_len(train_iter)\n","\n","    return train_iter\n","\n","def get_len(train):\n","\n","    for i, b in enumerate(train):\n","        pass\n","    \n","    return i"],"outputs":[],"metadata":{"id":"T0jx8nh0jGb5"}},{"cell_type":"markdown","source":["### 4. Cài đặt giải thuật tối ưu và huấn luyện mô hình"],"metadata":{"id":"MnqG6ZSo54ew"}},{"cell_type":"code","execution_count":null,"source":["# Optimizer\n","class CosineWithRestarts(torch.optim.lr_scheduler._LRScheduler):\n","    \"\"\"\n","    Cosine annealing with restarts.\n","    Parameters\n","    ----------\n","    optimizer : torch.optim.Optimizer\n","    T_max : int\n","        The maximum number of iterations within the first cycle.\n","    eta_min : float, optional (default: 0)\n","        The minimum learning rate.\n","    last_epoch : int, optional (default: -1)\n","        The index of the last epoch.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 optimizer: torch.optim.Optimizer,\n","                 T_max: int,\n","                 eta_min: float = 0.,\n","                 last_epoch: int = -1,\n","                 factor: float = 1.) -> None:\n","        # pylint: disable=invalid-name\n","        self.T_max = T_max\n","        self.eta_min = eta_min\n","        self.factor = factor\n","        self._last_restart: int = 0\n","        self._cycle_counter: int = 0\n","        self._cycle_factor: float = 1.\n","        self._updated_cycle_len: int = T_max\n","        self._initialized: bool = False\n","        super(CosineWithRestarts, self).__init__(optimizer, last_epoch)\n","\n","    def get_lr(self):\n","        \"\"\"Get updated learning rate.\"\"\"\n","        # HACK: We need to check if this is the first time get_lr() was called, since\n","        # we want to start with step = 0, but _LRScheduler calls get_lr with\n","        # last_epoch + 1 when initialized.\n","        if not self._initialized:\n","            self._initialized = True\n","            return self.base_lrs\n","\n","        step = self.last_epoch + 1\n","        self._cycle_counter = step - self._last_restart\n","\n","        lrs = [\n","            (\n","                self.eta_min + ((lr - self.eta_min) / 2) *\n","                (\n","                    np.cos(\n","                        np.pi *\n","                        ((self._cycle_counter) % self._updated_cycle_len) /\n","                        self._updated_cycle_len\n","                    ) + 1\n","                )\n","            ) for lr in self.base_lrs\n","        ]\n","\n","        if self._cycle_counter % self._updated_cycle_len == 0:\n","            # Adjust the cycle length.\n","            self._cycle_factor *= self.factor\n","            self._cycle_counter = 0\n","            self._updated_cycle_len = int(self._cycle_factor * self.T_max)\n","            self._last_restart = step\n","\n","        return lrs\n"],"outputs":[],"metadata":{"id":"hvXmikJB9swr"}},{"cell_type":"code","execution_count":null,"source":["!mkdir data\n","!wget https://raw.githubusercontent.com/SamLynnEvans/Transformer/master/data/english.txt\n","!mv english.txt data\n","!wget https://raw.githubusercontent.com/SamLynnEvans/Transformer/master/data/french.txt data/french.txt\n","!mv french.txt data"],"outputs":[],"metadata":{"id":"TRTtm5kO9swr"}},{"cell_type":"code","execution_count":null,"source":["\n","def get_model(opt, src_vocab, trg_vocab):\n","    \n","    assert opt.d_model % opt.heads == 0\n","    assert opt.dropout < 1\n","\n","    model = Transformer(src_vocab, trg_vocab, opt.d_model, opt.n_layers, opt.heads)\n","       \n","    if opt.load_weights is not None:\n","        print(\"loading pretrained weights...\")\n","        model.load_state_dict(torch.load(f'{opt.load_weights}/model_weights'))\n","    else:\n","        for p in model.parameters():\n","            if p.dim() > 1:\n","                nn.init.xavier_uniform_(p) \n","    \n","    if opt.device == 0:\n","        model = model.cuda()\n","    \n","    return model"],"outputs":[],"metadata":{"id":"LSOX2OEW9swr"}},{"cell_type":"code","execution_count":null,"source":["\"\"\" BAI TAP VE NHA \"\"\"\n","\n","import time\n","\n","def train_model(model, opt):\n","    ########################\n","    ##   YOUR CODE HERE   ##\n","    ########################\n","   \n","        \n","def main():\n","    opt = Opt()\n","    opt.src_data = \"data/english.txt\"\n","    opt.trg_data = \"data/french.txt\"\n","    opt.src_lang = \"en_core_web_sm\"\n","    opt.trg_lang = 'fr_core_news_sm'\n","    opt.epochs = 2\n","    opt.d_model=512\n","    opt.n_layers=6\n","    opt.heads=8\n","    opt.dropout=0.1\n","    opt.batchsize=1500\n","    opt.printevery=100\n","    opt.lr=0.0001\n","    opt.max_strlen=80\n","    opt.checkpoint = 0\n","    opt.no_cuda = False\n","    opt.load_weights = None\n","    \n","    opt.device = 0\n","    if opt.device == 0:\n","        assert torch.cuda.is_available()\n","    \n","    read_data(opt)\n","    SRC, TRG = create_fields(opt)\n","    opt.train = create_dataset(opt, SRC, TRG)\n","    model = get_model(opt, len(SRC.vocab), len(TRG.vocab)).to(device)\n","\n","    opt.optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr, betas=(0.9, 0.98), eps=1e-9)\n","\n","    if opt.checkpoint > 0:\n","        print(\"model weights will be saved every %d minutes and at end of epoch to directory weights/\"%(opt.checkpoint))\n","    \n","    train_model(model, opt)\n","\n","\n","    # for asking about further training use while true loop, and return\n","if __name__ == \"__main__\":\n","    main()"],"outputs":[],"metadata":{"id":"0Q2qOSP7jGb5"}}]}